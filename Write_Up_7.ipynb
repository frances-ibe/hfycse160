{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Work Plan Evaluation\n",
    "\n",
    "## Our original work plan is as follows:\n",
    "\n",
    "Our analysis will be performed through the following steps:\n",
    "\n",
    "(1)Data cleaning and management. \n",
    "\n",
    "In this step we will automatically parse through our data and extract the attributes we wish to carry forwards for the subsequent analyses. This step will most likely take us 4 hours of work and will only need to be performed once.\n",
    "\n",
    "(2) Basic statistics and correlations. \n",
    "\n",
    "Here we will seek to answer our first research question and gather information to answer the third question. We will perform any statistical analysis on the data that we have planned. Completing this step first can help inform the future analyses. This will likely take us a few hours of work.\n",
    "\n",
    "(3) In depth analysis and basic machine learning. \n",
    "\n",
    "We will next use sklearn to develop a predictive model and we will deeply dive into the problem of analyzing the spatial trends in the data. This step will comprise a bulk of our data analysis and we will likely spend a day or two tackling this analysis.\n",
    "\n",
    "(4) Optional machine learning step.\n",
    "\n",
    "In the event the previous three steps go very smoothly we will use TensorFlow to train a model to predict the best zip code to open a restaurant in a given city. This will probably take a couple of days and is a bit optimistic.\n",
    "\n",
    "## Evaluation\n",
    "We seriously underestimated the amount of time that it would take to write the scripts to read in and organize data from our three datasets into pandas data frames that included the information necessary for our analysis. We estimated that this would take roughly 4 hours of work and it ended up taking about 6 hours of work. Another reason we misunderestimated the time for this task is that we as a team spent a fair amount of time learning how to use git. We now understand how to generate efficient workflows in git and create branches, such that when we commit, we run into as little merge conflicts as possible.\n",
    "\n",
    "The basic statistics and correlations also took longer than expected, as we predicted that we would complete our analysis in a few hours, but it took about a day and half. This is mostly due to us learning new functions within the modules that we implemented for working with large datasets, specifically pandas. Furthermore, we predicted that the bulk of our analysis would be done in the regression analysis, however we ended up focusing more heavily on the basic statistical analyses (chi-squared, pearsonâ€™s correlation coefficient, etc.), which led to a longer time spent on this portion of our project. We ended up successfully generating a linear regression model using the sklearn module, but did not spend as much time on this analysis as we thought was previously necessary. \n",
    "\n",
    "With the extra time spent on the basic statistical analysis we found that we did not have time to complete our optional machine learning step although we did generate a rough model using the sklearn API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
